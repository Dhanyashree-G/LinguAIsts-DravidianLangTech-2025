{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171a8de8-25cc-448e-98f1-219a312b80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp081\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp081\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp081\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Naive Bayes Classifier:\n",
      "Cross-Validation Accuracy: 0.6376 ± 0.0620\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      1728\n",
      "           1       0.86      0.91      0.88      1834\n",
      "\n",
      "    accuracy                           0.88      3562\n",
      "   macro avg       0.88      0.87      0.87      3562\n",
      "weighted avg       0.88      0.88      0.87      3562\n",
      "\n",
      "Accuracy: 0.8751\n",
      "Predictions saved to C:\\Users\\hp081\\Documents\\AWM_test_predictions_naive_bayes.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(r\"C:\\Users\\hp081\\Downloads\\AWM_train.csv\")\n",
    "dev_data = pd.read_csv(r\"C:\\Users\\hp081\\Downloads\\AWM_dev.csv\")\n",
    "test_data = pd.read_csv(r\"C:\\Users\\hp081\\Downloads\\AWM_test_without_labels.csv\")\n",
    "\n",
    "# Combine train and dev datasets\n",
    "train_data = pd.concat([train_data, dev_data], ignore_index=True)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data['Text'] = train_data['Text'].apply(preprocess_text)\n",
    "test_data['Text'] = test_data['Text'].apply(preprocess_text)\n",
    "\n",
    "# Encode labels\n",
    "train_data['Class'] = train_data['Class'].map({'Abusive': 1, 'Non-Abusive': 0})\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english', smooth_idf=True)\n",
    "X = train_data['Text']\n",
    "y = train_data['Class']\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "print(\"\\nEvaluating Naive Bayes Classifier:\")\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Evaluate with cross-validation\n",
    "scores = cross_val_score(naive_bayes_model, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "\n",
    "# Fit the model on the full training data\n",
    "naive_bayes_model.fit(X_tfidf, y)\n",
    "y_pred = naive_bayes_model.predict(X_tfidf)\n",
    "\n",
    "# Print Classification Report and Accuracy\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "\n",
    "# Predict on Test Data\n",
    "X_test_tfidf = vectorizer.transform(test_data['Text'])\n",
    "test_predictions = naive_bayes_model.predict(X_test_tfidf)\n",
    "\n",
    "# Map predicted classes back to labels\n",
    "label_mapping = {0: 'Non-Abusive', 1: 'Abusive'}\n",
    "test_data['Predicted_Class_Label'] = test_predictions  # Add predictions as a column first\n",
    "test_data['Predicted_Class_Label'] = test_data['Predicted_Class_Label'].map(label_mapping)  # Map to labels\n",
    "\n",
    "# Save predictions as a CSV file\n",
    "output_dir = r\"C:\\Users\\hp081\\Documents\"\n",
    "output_csv_path = os.path.join(output_dir, \"AWM_test_predictions_naive_bayes.csv\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save labels in CSV format, including all relevant columns\n",
    "test_data[['id', 'Text', 'Predicted_Class_Label']].to_csv(output_csv_path, index=False)\n",
    "print(f\"Predictions saved to {output_csv_path}\")\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess_text_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Function to predict if the input comment is abusive or not\n",
    "def predict_comment(comment, model, vectorizer):\n",
    "    # Preprocess the input comment\n",
    "    processed_comment = preprocess_text_input(comment)\n",
    "\n",
    "    # Transform the comment using the TF-IDF vectorizer\n",
    "    comment_vector = vectorizer.transform([processed_comment])\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(comment_vector)\n",
    "\n",
    "    # Map the prediction to the label\n",
    "    label_mapping = {0: 'Non-Abusive', 1: 'Abusive'}\n",
    "    predicted_label = label_mapping[prediction[0]]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be399fe-676d-4904-a5e4-d364b84f8cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
